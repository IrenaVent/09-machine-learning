{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  <span style=\"color:#5D8BF4\"> Irena Vent </span>\n",
    "\n",
    "# <span style=\"color:#051367\"> Machine Learning</span>\n",
    "\n",
    "<span style=\"color:#051367\"> **Dataset**: Airbnb </span>\n",
    "\n",
    "<span style=\"color:#051367\"> **Objetivo**: Predecir el precio de un airbnb situado Madrid</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline\n",
    "\n",
    "cm = plt.cm.RdBu\n",
    "cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(confmat):\n",
    "    fig, ax = plt.subplots(figsize=(7, 7))\n",
    "    ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.5)\n",
    "    for i in range(confmat.shape[0]):\n",
    "        for j in range(confmat.shape[1]):\n",
    "            ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
    "\n",
    "    plt.xlabel('predicted label')\n",
    "    plt.ylabel('true label')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <span style=\"color:#5D8BF4\"> Cargamos nuestro dataset con el objetivo de: </span>\n",
    "    \n",
    "1. Filtrar el dataset por Madird (Spain); \n",
    "2. Comprobar si existen variables que puedan ser descartadas previo al análisis exploratior de datos, por ejemplo: ids, urls, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba = pd.read_csv('./data/airbnb-listings.csv', sep=';', decimal='.')\n",
    "\n",
    "#pd.set_option('display.max_columns', None)\n",
    "#prueba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14780, 89)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prueba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13234, 40)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eliminamos las muestras que contienen NaN en las columnas indicadas\n",
    "prueba = prueba.dropna(subset=['Country', 'City'])\n",
    "\n",
    "# filtramos por Spian y Madrid\n",
    "prueba = prueba.loc[prueba['Country'] == 'Spain']\n",
    "prueba = prueba[prueba[\"City\"].str.contains(\"Madrid\")]\n",
    "\n",
    "#print(f'Dimensión dataframe --> {prueba.shape}')\n",
    "#print(f'Valores únicos en Country --> {prueba[\"Country\"].unique()}')\n",
    "#print(f'Valores únicos en City --> {prueba[\"City\"].unique()}')\n",
    "\n",
    "# eliminamos columnas\n",
    "prueba = prueba.drop(['ID', 'Listing Url', 'Scrape ID', 'Last Scraped', 'Name', 'Summary', 'Space', 'Description',\n",
    "                      'Experiences Offered', 'Neighborhood Overview','Zipcode' , 'Notes', 'Transit', 'Access', \n",
    "                      'Interaction', 'House Rules', 'Thumbnail Url', 'Medium Url', 'Picture Url', 'XL Picture Url',\n",
    "                      'Host ID', 'Host URL', 'Host Name', 'Host Since', 'Host Location', 'Host About','Amenities', \n",
    "                      'Host Thumbnail Url', 'Host Picture Url', 'Host Neighbourhood','Host Listings Count', \n",
    "                      'Host Total Listings Count', 'Host Verifications', 'Street', 'City', 'State', 'Market',\n",
    "                      'Smart Location', 'Country Code', 'Country', 'First Review', 'Last Review', 'Calendar Updated', \n",
    "                      'Calendar last Scraped', 'License', 'Jurisdiction Names', 'Calculated host listings count',\n",
    "                      'Geolocation', 'Features'], axis = 1)\n",
    "\n",
    "prueba.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#5D8BF4\"> **Divsión del dataset en train y test** para el desarrollo de análisis exploratorio de datos. Que se realizará únicamente sobre el subconjunto de train. Posteriormente, en la validación del modelo elegido, las decisiones tomadas sobre train se aplicaran al subconjunto de test. </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del dataset de training: (10587, 40)\n",
      "Dimensiones del dataset de test: (2647, 40)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#full_df = pd.read_csv('./airbnb-listings-extract.csv', sep=';', decimal='.')\n",
    "train, test = train_test_split(prueba, test_size=0.2, shuffle=True, random_state=0)\n",
    "\n",
    "print(f'Dimensiones del dataset de training: {train.shape}')\n",
    "print(f'Dimensiones del dataset de test: {test.shape}')\n",
    "\n",
    "# Guardamos\n",
    "train.to_csv('./train.csv', sep=';', decimal='.', index=False)\n",
    "test.to_csv('./test.csv', sep=';', decimal='.', index=False)\n",
    "\n",
    "# A partir de este momento cargamos el dataset de train y trabajamos ÚNICAMENTE con él. \n",
    "df_train = pd.read_csv('./train.csv', sep=';', decimal='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#5D8BF4\"> **Análisis exploratior de los datos** </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "prueba.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.isnull().any()\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#5D8BF4\"> **Primeras observaciones**</span>\n",
    "\n",
    "- Existen varibles, como son: Host Response Time, Neighbourhood, Neighbourhood Cleansed, Neighbourhood Group Cleansed, Property Type, Bed Type, Amenities, y Cancellation Policy, todas ellas de tipo **object** que deben ser transformadas y/o categorizadas;\n",
    "\n",
    "- Las variables Host Acceptance Rate y Has Availability pueden ser eliminadas al tener todas sus muestras ausentes; \n",
    "\n",
    "- La variable objetivo Price tiene 9 muestras con valores ausentes, que se eliminarán;\n",
    "       \n",
    "- La varieble Square Feet debe ser transformada a Square Meter observamos que más de 96% de sus muestras están ausentes, por lo que decidimos eliminar dicha columna;\n",
    "    \n",
    "- La varible Zipcode parece tener datos erróneos, reisar y eliminar valores ausente;\n",
    "    \n",
    "- Imputar los valores ausentes con la moda en Bed, Bedroom y Bathroom, el 75% de la muestra está dentro del rango, pues parece haber algún autlier;\n",
    "    \n",
    "- Sobre las variables Neighbourhood, Neighbourhood Cleansed y Neighbourhood Group Cleansed ver contenido de cada varaibles para decidir si es necesario eliminar alguna de ellas;\n",
    "    \n",
    "- Para las variables Weekly Price y Monthly Price analizar con un estudio de correlación y decidir si se pueden eliminar;\n",
    "    \n",
    "- Muchas de las variabbles (Accommodates, Square Feet, Weekly Price, Monthly Price, Security Deposit, Number of Reviews, etc) presentan valores dispares, por lo que sería necesario explorar los datos para ecnontrar posibles outliers;\n",
    "    \n",
    "- Todas las variables Review excepto Number of Reviews, presentan valores ausentes, la imputación según los datos, puede ser a través de las media o valor meas frecuente. Pero sería necesario valorar la opción de eliminar alguna de dichas variables con un estudio de correlaciones; </span>\n",
    "\n",
    "<span style=\"color:#5D8BF4\"> **Gráfico de correlaciones** valorar si podemos eliminar alguna variables más en este punto.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = np.abs(df_train.corr())\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask,vmin = 0.0, vmax=1.0, center=0.5,\n",
    "            linewidths=.1, cmap=\"YlGnBu\", cbar_kws={\"shrink\": .8})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminamos las columnas con valores ausentes y alta correlación entre variables predictoras\n",
    "# evitar la colinealidad\n",
    "df_train = df_train.drop(['Host Acceptance Rate', 'Host Response Time', 'Has Availability', 'Square Feet', \n",
    "                          'Neighbourhood', 'Neighbourhood Cleansed', 'Weekly Price', 'Monthly Price', \n",
    "                          'Has Availability', 'Availability 30', 'Availability 60', 'Availability 365',\n",
    "                          'Review Scores Accuracy', 'Review Scores Checkin','Review Scores Communication', \n",
    "                          'Reviews per Month', 'Review Scores Value'], axis = 1)\n",
    "\n",
    "# eliminamos 9 muestras con Price NaN\n",
    "df_train = df_train.dropna(subset=['Price'])\n",
    "\n",
    "print(f'Porcentaje de muestras eliminadas: {round((10587-df_train.shape[0])/10587*100,4)} %')\n",
    "print(f'Tamaño df_train: {df_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
